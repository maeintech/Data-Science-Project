{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"rNG4bhZDsUZw","executionInfo":{"status":"ok","timestamp":1721920515258,"user_tz":-60,"elapsed":3366,"user":{"displayName":"Maero Evru","userId":"11355386806162368954"}}},"outputs":[],"source":["#import libraries\n","import os\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from statsmodels.tsa.seasonal import seasonal_decompose"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1362,"status":"ok","timestamp":1721920516615,"user":{"displayName":"Maero Evru","userId":"11355386806162368954"},"user_tz":-60},"id":"4RXJqTITLVGw","outputId":"aa492eca-284f-44f7-dc56-69f6e1001eb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#Mount Google Drive to access dataset\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#Look through all folders in the \"Project\" folder to access dataset\n","folder_path = '/content/drive/MyDrive/Project'\n","\n","data = []\n","\n","for root, dirs, files in os.walk(folder_path):\n","    for filename in files:\n","        if filename.endswith('.txt'):\n","            file_path = os.path.join(root, filename)\n","            date = os.path.splitext(filename)[0]  # Extract date from filename\n","            try:\n","                df = pd.read_csv(file_path, delimiter='\\s+', skiprows=[0, 2], encoding='latin1')\n","                df = df.iloc[:, :16]\n","                df.columns = ['Time', 'Wind Dir', 'Wind Spd', 'Hum In', 'Humidity', 'Temp In', 'Temp', 'Raw Barom', 'Temp Ch1', 'Hum Ch1', 'Temp Ch2', 'Hum Ch2', 'UV', 'Solar Radiation', 'Dew Point', 'Rain Rate']\n","                df.insert(0, 'Date', pd.to_datetime(date, format='%y%m%d').strftime('%d-%m-%y'))\n","\n","                data.append(df)\n","            except Exception as e:\n","                print(f\"Error processing file {file_path}: {e}\")"],"metadata":{"id":"LHnNNPQhlWzw","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1721920620036,"user_tz":-60,"elapsed":103426,"user":{"displayName":"Maero Evru","userId":"11355386806162368954"}},"outputId":"d4703571-31e8-4158-a8bf-9c3ae4f3633c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Error processing file /content/drive/MyDrive/Project/Dataset_3/120825.txt: No columns to parse from file\n","Error processing file /content/drive/MyDrive/Project/Dataset_3/121220.txt: Error tokenizing data. C error: Expected 30 fields in line 689, saw 31\n","\n"]}]},{"cell_type":"code","source":["# Concatenate all data into a single DataFrame\n","data = pd.concat(data, ignore_index=True)\n","\n","# Convert 'date' and 'Time' columns to datetime\n","data['Date'] = pd.to_datetime(data['Date'], format='%d-%m-%y')\n","data['Time'] = pd.to_datetime(data['Time'], format='%H:%M').dt.time\n","data.sort_values(by=['Date', 'Time'], inplace=True)\n","data.set_index('Date', inplace=True)\n","\n","print(data.head())"],"metadata":{"id":"SZF9P5KS_JOM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cutoff = pd.to_datetime('2012-12-20')\n","\n","data1 = data.loc[:cutoff]\n","data2 = data.loc[cutoff:]\n","\n","data2 = data2.iloc[:, :13]\n","data2.columns = ['Time', 'Wind Dir', 'Wind Spd', 'Hum In', 'Humidity', 'Temp In', 'Temp', 'Raw Barom', 'UV', 'Solar Radiation', 'Dew Point', 'Daily Rain', 'Rain Rate']\n","data2"],"metadata":{"id":"5RIrbgAQPucD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.set_option('display.max_info_columns', 100)\n","pd.set_option('display.max_info_rows', 10000000)\n","data1.info(verbose=True)"],"metadata":{"id":"GWGWakHZg-jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data2.info(verbose=True)"],"metadata":{"id":"j5LYXv8ESjcx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1.describe()"],"metadata":{"id":"T0uwIDvfKuoy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data2.describe()"],"metadata":{"id":"CViDSEAlTnDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numeric_data = data2.select_dtypes(include='number')\n","corr_matrix = numeric_data.corr()\n","\n","plt.figure(figsize=(12, 8))\n","\n","sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n","\n","plt.title('Correlation Heatmap')\n","plt.xticks(rotation=45, ha='right')\n","plt.yticks(rotation=0)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"xCoqyRylV16G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create a copy of data2 for Time-series analysis\n","data2_copy = data2.copy()\n","data2_copy.index = pd.to_datetime(data2_copy.index, format='%Y-%m-%d')\n","data2_copy['Time'] = pd.to_datetime(data2_copy['Time'], format='%H:%M:%S').dt.time\n","\n","date_str = data2_copy.index.date.astype(str)  # Convert index dates to string\n","time_str = data2_copy['Time'].astype(str)     # Convert 'Time' to string\n","datetime_str = [f\"{date} {time}\" for date, time in zip(date_str, time_str)]\n","\n","data2_copy.index = pd.to_datetime(datetime_str)\n","\n","# Drop the old 'Time' column\n","data2_copy.drop(columns=['Time'], inplace=True)"],"metadata":{"id":"9A6E4hxwwz4Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def time_series_analysis(data2_copy, column_name):\n","    # Check if column exists in the dataframe\n","    if column_name not in data2_copy.columns:\n","        raise ValueError(f\"Column '{column_name}' not found in the dataframe.\")\n","\n","    # Plot the time series data\n","    plt.figure(figsize=(14, 7))\n","    plt.plot(data2_copy.index, data2_copy[column_name], label=column_name)\n","    plt.title(f'Time Series Plot of {column_name}')\n","    plt.xlabel('Date')\n","    plt.ylabel(column_name)\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","    # Resample to daily frequency and plot\n","    data2_daily = data2_copy.resample('D').mean()\n","    plt.figure(figsize=(14, 7))\n","    plt.plot(data2_daily.index, data2_daily[column_name], label=f'Daily Average {column_name}')\n","    plt.title(f'Daily Average Time Series Plot of {column_name}')\n","    plt.xlabel('Date')\n","    plt.ylabel(column_name)\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","    # Seasonal Decomposition\n","    decomposition = seasonal_decompose(data2_daily[column_name].dropna(), model='additive', period = 365)\n","    plt.figure(figsize=(14, 10))\n","    plt.subplot(4, 1, 1)\n","    plt.plot(decomposition.observed)\n","    plt.title('Observed')\n","\n","    plt.subplot(4, 1, 2)\n","    plt.plot(decomposition.trend)\n","    plt.title('Trend')\n","\n","    plt.subplot(4, 1, 3)\n","    plt.plot(decomposition.seasonal)\n","    plt.title('Seasonal')\n","\n","    plt.subplot(4, 1, 4)\n","    plt.plot(decomposition.resid)\n","    plt.title('Residual')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Rolling Statistics\n","    rolling_mean = data2_copy[column_name].rolling(window=30).mean()\n","    rolling_std = data2_copy[column_name].rolling(window=30).std()\n","\n","    plt.figure(figsize=(14, 7))\n","    plt.plot(data2_copy.index, data2_copy[column_name], label='Original')\n","    plt.plot(data2_copy.index, rolling_mean, label='Rolling Mean', color='orange')\n","    plt.plot(data2_copy.index, rolling_std, label='Rolling Std', color='red')\n","    plt.title(f'Rolling Statistics of {column_name}')\n","    plt.xlabel('Date')\n","    plt.ylabel(column_name)\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","# Example usage\n","time_series_analysis(data2_copy, 'Temp')\n","time_series_analysis(data2_copy, 'Rain Rate')"],"metadata":{"id":"FWaicaPO5AAe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#might want to do this for the daily data that has been averaged\n","rolling_mean = data2_copy['Temp'].rolling(window=30).mean()\n","rolling_std = data2_copy['Temp'].rolling(window=30).std()\n","print(rolling_mean)\n","print(rolling_std)"],"metadata":{"id":"l93k-L1WV0N3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data2_copy"],"metadata":{"id":"Z7hhFtb1a3vi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Creating a subset of the data with Temp, Rain rate, Humidity, Solar radiation and wind speed\n","climate_data = data2[['Time', 'Temp', 'Rain Rate', 'Humidity', 'Solar Radiation', 'Wind Spd']]\n","climate_data"],"metadata":{"id":"0WOYLlgeTsUq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numeric_columns = climate_data.select_dtypes(include='number').columns\n","climate_data_numeric = climate_data[numeric_columns]\n","\n","daily_average = climate_data_numeric.groupby(climate_data.index).mean()\n","daily_average"],"metadata":{"id":"WmvMp0lHUGuv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PiJnnIfRFbFC"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPONxKPBpIYuk4Wb+fJRv5Z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}